{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, some random practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7444,  1.0120,  0.3675,  2.6592],\n",
       "        [-0.9483, -1.0301, -0.1990, -0.2448],\n",
       "        [-0.7577,  1.1288, -0.9627,  0.4792],\n",
       "        [-1.9023, -0.7524, -0.5739, -0.4064]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4, 4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask with only triangular booleans:\n",
      "tensor([[ True, False, False, False],\n",
      "        [ True,  True, False, False],\n",
      "        [ True,  True,  True, False],\n",
      "        [ True,  True,  True,  True]])\n",
      "\n",
      "Mask after doing == 0:\n",
      "tensor([[False,  True,  True,  True],\n",
      "        [False, False,  True,  True],\n",
      "        [False, False, False,  True],\n",
      "        [False, False, False, False]])\n",
      "\n",
      "Masked matrix:\n",
      "tensor([[-0.7444,    -inf,    -inf,    -inf],\n",
      "        [-0.9483, -1.0301,    -inf,    -inf],\n",
      "        [-0.7577,  1.1288, -0.9627,    -inf],\n",
      "        [-1.9023, -0.7524, -0.5739, -0.4064]])\n"
     ]
    }
   ],
   "source": [
    "mask = torch.tril(torch.ones_like(a, dtype=torch.bool))\n",
    "print(f\"Mask with only triangular booleans:\\n{mask}\")\n",
    "mask = mask == 0  # logic: True == 0 is False, False == 0 is True\n",
    "print(f\"\\nMask after doing == 0:\\n{mask}\")\n",
    "b = a.masked_fill(mask=mask, value=torch.tensor(float(\"-inf\")))\n",
    "print(f\"\\nMasked matrix:\\n{b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5204, 0.4796, 0.0000, 0.0000],\n",
       "        [0.1189, 0.7843, 0.0969, 0.0000],\n",
       "        [0.0807, 0.2547, 0.3045, 0.3600]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.softmax(b, dim=-1)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to build the masked self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "token_embed_w_pos = torch.randn(5, 5)\n",
    "\n",
    "mask = torch.tril(torch.ones_like(token_embed_w_pos, dtype=torch.bool))\n",
    "mask = mask == 0\n",
    "\n",
    "\n",
    "class MaskedSelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim=5, row_index=0, col_index=1):\n",
    "        super().__init__()\n",
    "        self.W_q = nn.Linear(in_features=embed_dim, out_features=embed_dim, bias=False)\n",
    "        self.W_k = nn.Linear(in_features=embed_dim, out_features=embed_dim, bias=False)\n",
    "        self.W_v = nn.Linear(in_features=embed_dim, out_features=embed_dim, bias=False)\n",
    "        self.row_index = row_index\n",
    "        self.col_index = col_index\n",
    "\n",
    "    def forward(self, token_embeddings, mask=None):\n",
    "        q = self.W_q(token_embeddings)\n",
    "        k = self.W_k(token_embeddings)\n",
    "        v = self.W_v(token_embeddings)\n",
    "\n",
    "        sims = torch.matmul(\n",
    "            q, torch.transpose(k, dim0=self.row_index, dim1=self.col_index)\n",
    "        )\n",
    "\n",
    "        scaled_sims = sims / torch.tensor(k.shape[self.col_index] ** 0.5)\n",
    "\n",
    "        if mask is not None:\n",
    "            scaled_sims = scaled_sims.masked_fill(\n",
    "                mask=mask, value=torch.tensor(float(\"-inf\"))\n",
    "            )\n",
    "\n",
    "        attn_percents = torch.softmax(input=scaled_sims, dim=self.col_index)\n",
    "        self_attn_scores = attn_percents @ v\n",
    "        return self_attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784],\n",
       "         [-1.2345, -0.0431, -1.6047, -0.7521, -0.6866],\n",
       "         [-0.4934,  0.2415, -1.1109,  0.0915, -2.3169],\n",
       "         [-0.2168, -1.3847, -0.3957,  0.8034, -0.6216],\n",
       "         [-0.5920, -0.0631, -0.8286,  0.3309, -1.5576]]),\n",
       " tensor([[False,  True,  True,  True,  True],\n",
       "         [False, False,  True,  True,  True],\n",
       "         [False, False, False,  True,  True],\n",
       "         [False, False, False, False,  True],\n",
       "         [False, False, False, False, False]]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embed_w_pos, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_selfattn = MaskedSelfAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.7145e-01,  1.1592e+00, -3.9426e-01, -5.4707e-01,  5.0947e-01],\n",
       "        [ 5.7437e-01,  7.7056e-01,  2.8447e-02,  1.2527e-01,  6.6998e-01],\n",
       "        [ 6.2325e-01,  8.1523e-01,  1.0536e-01, -1.6011e-01,  6.4922e-01],\n",
       "        [ 1.4171e-01,  4.4811e-01,  3.9255e-01,  1.4965e-05,  4.4730e-01],\n",
       "        [ 2.7494e-01,  5.2278e-01,  3.0604e-01, -9.1794e-02,  4.7333e-01]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_selfattn(token_embed_w_pos, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### SO, basically, what I did was..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True],\n",
       "        [False, False,  True,  True,  True],\n",
       "        [False, False, False,  True,  True],\n",
       "        [False, False, False, False,  True],\n",
       "        [False, False, False, False, False]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Create a mask tensor\n",
    "\n",
    "randinput = torch.randn(5, 5)\n",
    "mask2 = torch.tril(input=torch.ones_like(randinput, dtype=bool))\n",
    "mask2 = mask2 == 0\n",
    "mask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0853,  0.7481, -0.1636, -0.9086,  0.3130],\n",
       "        [ 0.8050, -1.1134,  0.5258, -1.2000, -0.8326],\n",
       "        [-0.8129,  0.9700, -0.6758,  0.2043, -0.0265],\n",
       "        [-0.4138,  0.5184,  0.3418, -2.7016,  0.0666],\n",
       "        [-0.9120,  0.3682,  0.7050, -1.0838, -0.3889]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.8720, 0.1280, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1235, 0.7348, 0.1417, 0.0000, 0.0000],\n",
       "        [0.1733, 0.4402, 0.3689, 0.0176, 0.0000],\n",
       "        [0.0822, 0.2957, 0.4141, 0.0692, 0.1387]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Apply the mask to the input\n",
    "\n",
    "masked_randinput = randinput.masked_fill(mask=mask2, value=torch.tensor(float(\"-inf\")))\n",
    "masked_randinput_softmax = torch.softmax(masked_randinput, dim=-1)\n",
    "masked_randinput_softmax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
