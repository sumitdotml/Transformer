{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For a single text:\n",
      "torch.Size([1, 4, 512])\n",
      "tensor([[[ 1.3528,  0.1661,  0.8340,  ..., -0.2221, -0.8318, -0.7485],\n",
      "         [-1.0376, -1.7886, -0.6090,  ..., -1.0526, -1.2898,  0.9389],\n",
      "         [ 2.0893, -0.2985,  1.1456,  ...,  0.3236, -2.9462,  0.0985],\n",
      "         [-1.3550,  0.2938,  0.8257,  ...,  1.2434,  0.2497,  1.2228]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "[1212, 318, 257, 10586]\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 1.3528,  0.1661,  0.8340,  ..., -0.2221, -0.8318, -0.7485],\n",
      "         [-1.0376, -1.7886, -0.6090,  ..., -1.0526, -1.2898,  0.9389],\n",
      "         [ 2.0893, -0.2985,  1.1456,  ...,  0.3236, -2.9462,  0.0985],\n",
      "         [-1.3550,  0.2938,  0.8257,  ...,  1.2434,  0.2497,  1.2228]],\n",
      "\n",
      "        [[-0.2861,  0.8211,  0.6507,  ..., -0.5635, -0.1463, -0.3444],\n",
      "         [-0.0956,  0.7857,  1.3993,  ...,  0.0037,  1.3891, -0.2660],\n",
      "         [-0.0971, -0.4761,  0.0094,  ...,  1.1272, -0.1969, -0.2823],\n",
      "         [ 0.3679,  1.2539, -0.9097,  ...,  0.7282, -0.7757, -1.1468]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "[[1212, 318, 257, 10586], [32, 3621, 6891, 6508]]\n"
     ]
    }
   ],
   "source": [
    "input_text = []\n",
    "input_text1 = 'This is a keyboard'\n",
    "input_text2 = 'A nice coffee cup'\n",
    "input_text.append(input_text1)\n",
    "input_text.append(input_text2)\n",
    "\n",
    "# for a single text\n",
    "token_ids_single, input_embeddings_single = tokenize_text(input_text[0])\n",
    "print(\"\\nFor a single text:\")\n",
    "print(input_embeddings_single.shape)\n",
    "print(input_embeddings_single)\n",
    "print(token_ids_single)\n",
    "\n",
    "# for batched processing\n",
    "token_ids, input_embeddings = tokenize_batch(input_text)\n",
    "print(input_embeddings.shape)\n",
    "print(input_embeddings)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3528,  1.1661,  0.8340,  ...,  0.7779, -0.8318,  0.2515],\n",
       "         [-0.1962, -1.2189,  0.1930,  ..., -0.0526, -1.2898,  1.9389],\n",
       "         [ 2.9986, -0.6494,  2.1037,  ...,  1.3236, -2.9462,  1.0985],\n",
       "         [-1.2139, -0.6757,  1.1685,  ...,  2.2434,  0.2497,  2.2228]],\n",
       "\n",
       "        [[-0.2861,  1.8211,  0.6507,  ...,  0.4365, -0.1463,  0.6556],\n",
       "         [ 0.7458,  1.3554,  2.2012,  ...,  1.0037,  1.3891,  0.7340],\n",
       "         [ 0.8122, -0.8270,  0.9675,  ...,  2.1272, -0.1969,  0.7177],\n",
       "         [ 0.5090,  0.2844, -0.5669,  ...,  1.7282, -0.7757, -0.1468]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_embedding = positional_encoding(input_embeddings=input_embeddings)\n",
    "encoded_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving on to the encoder block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads) -> None:\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0, f\"\\nNumber of embedding dimensions is not divisible by the number of heads.\\nEmbedding dimensions (d_model): {d_model}, Number of heads: {num_heads}\\n{d_model} is not divisible by {num_heads}.\"\n",
    "        self.heads = num_heads\n",
    "    def forward(self, encoded_embedding):\n",
    "        num_batches, seq_length, d_model = encoded_embedding.shape\n",
    "        batches = encoded_embedding\n",
    "        return batches, seq_length, d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nNumber of embedding dimensions is not divisible by the number of heads.\nEmbedding dimensions (d_model): 512, Number of heads: 9\n512 is not divisible by 9.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mhead \u001b[38;5;241m=\u001b[39m \u001b[43mMultiHeadAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m, in \u001b[0;36mMultiHeadAttention.__init__\u001b[0;34m(self, d_model, num_heads)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, d_model, num_heads) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m d_model \u001b[38;5;241m%\u001b[39m num_heads \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNumber of embedding dimensions is not divisible by the number of heads.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEmbedding dimensions (d_model): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Number of heads: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_heads\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00md_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not divisible by \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_heads\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads \u001b[38;5;241m=\u001b[39m num_heads\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNumber of embedding dimensions is not divisible by the number of heads.\nEmbedding dimensions (d_model): 512, Number of heads: 9\n512 is not divisible by 9."
     ]
    }
   ],
   "source": [
    "mhead = MultiHeadAttention(d_model=d_model, num_heads=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiHead = MultiHeadAttention(d_model=d_model, num_heads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches' shape: torch.Size([2, 4, 512])\n",
      "i.e., 2 batches of 4 tokens each, each token of dimensions 512\n",
      "\n",
      "Batches:\n",
      "tensor([[[ 1.3528,  1.1661,  0.8340,  ...,  0.7779, -0.8318,  0.2515],\n",
      "         [-0.1962, -1.2189,  0.1930,  ..., -0.0526, -1.2898,  1.9389],\n",
      "         [ 2.9986, -0.6494,  2.1037,  ...,  1.3236, -2.9462,  1.0985],\n",
      "         [-1.2139, -0.6757,  1.1685,  ...,  2.2434,  0.2497,  2.2228]],\n",
      "\n",
      "        [[-0.2861,  1.8211,  0.6507,  ...,  0.4365, -0.1463,  0.6556],\n",
      "         [ 0.7458,  1.3554,  2.2012,  ...,  1.0037,  1.3891,  0.7340],\n",
      "         [ 0.8122, -0.8270,  0.9675,  ...,  2.1272, -0.1969,  0.7177],\n",
      "         [ 0.5090,  0.2844, -0.5669,  ...,  1.7282, -0.7757, -0.1468]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batches, batch_size, seq_length, d_model = multiHead(encoded_embedding)\n",
    "print(f\"\"\"Batches' shape: {batches.shape}\n",
    "i.e., {batch_size} batches of {seq_length} tokens each, each token of dimensions {d_model}.\n",
    "\n",
    "Batches:\n",
    "{batches}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
