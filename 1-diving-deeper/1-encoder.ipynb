{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For a single text:\n",
      "torch.Size([1, 4, 512])\n",
      "tensor([[[ 0.8917,  1.3933, -0.8909,  ..., -1.2700, -1.5286, -1.7189],\n",
      "         [-0.6776, -0.3867, -0.1106,  ..., -2.6652, -0.0245,  0.3272],\n",
      "         [-0.5232, -0.2722,  1.0417,  ..., -0.0192, -1.4332,  1.5941],\n",
      "         [-0.7227,  1.5541,  0.2964,  ...,  0.0488,  0.0632,  0.7642]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "[1212, 318, 257, 10586]\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 0.8917,  1.3933, -0.8909,  ..., -1.2700, -1.5286, -1.7189],\n",
      "         [-0.6776, -0.3867, -0.1106,  ..., -2.6652, -0.0245,  0.3272],\n",
      "         [-0.5232, -0.2722,  1.0417,  ..., -0.0192, -1.4332,  1.5941],\n",
      "         [-0.7227,  1.5541,  0.2964,  ...,  0.0488,  0.0632,  0.7642]],\n",
      "\n",
      "        [[ 0.2053, -0.6716,  1.1073,  ..., -1.2991, -0.6190, -0.0838],\n",
      "         [ 0.3256, -0.3149, -0.1741,  ..., -0.1790,  1.5053,  1.8777],\n",
      "         [ 0.7934,  1.6292,  0.5403,  ...,  0.1618, -0.0089, -0.6414],\n",
      "         [ 0.1415, -1.4723,  0.5583,  ...,  1.0058,  0.8063,  0.1839]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "[[1212, 318, 257, 10586], [32, 3621, 6891, 6508]]\n"
     ]
    }
   ],
   "source": [
    "input_text = []\n",
    "input_text1 = \"This is a keyboard\"\n",
    "input_text2 = \"A nice coffee cup\"\n",
    "input_text.append(input_text1)\n",
    "input_text.append(input_text2)\n",
    "\n",
    "# for a single text\n",
    "token_ids_single, input_embeddings_single = tokenize_text(input_text[0])\n",
    "print(\"\\nFor a single text:\")\n",
    "print(input_embeddings_single.shape)\n",
    "print(input_embeddings_single)\n",
    "print(token_ids_single)\n",
    "\n",
    "# for batched processing\n",
    "token_ids, input_embeddings = tokenize_batch(input_text)\n",
    "print(input_embeddings.shape)\n",
    "print(input_embeddings)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8917,  2.3933, -0.8909,  ..., -0.2700, -1.5286, -0.7189],\n",
       "         [ 0.1638,  0.1830,  0.6913,  ..., -1.6652, -0.0245,  1.3272],\n",
       "         [ 0.3861, -0.6231,  1.9998,  ...,  0.9808, -1.4332,  2.5941],\n",
       "         [-0.5816,  0.5846,  0.6392,  ...,  1.0488,  0.0632,  1.7642]],\n",
       "\n",
       "        [[ 0.2053,  0.3284,  1.1073,  ..., -0.2991, -0.6190,  0.9162],\n",
       "         [ 1.1671,  0.2548,  0.6279,  ...,  0.8210,  1.5053,  2.8777],\n",
       "         [ 1.7027,  1.2783,  1.4984,  ...,  1.1618, -0.0089,  0.3586],\n",
       "         [ 0.2827, -2.4418,  0.9011,  ...,  2.0058,  0.8063,  1.1839]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_embedding = positional_encoding(input_embeddings=input_embeddings)\n",
    "encoded_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving on to the encoder block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionV1(nn.Module):\n",
    "    def __init__(self, d_model=512, num_heads=8) -> None:\n",
    "        super().__init__()\n",
    "        assert (\n",
    "            d_model % num_heads == 0\n",
    "        ), f\"\\nNumber of embedding dimensions is not divisible by the number of heads.\\nEmbedding dimensions (d_model): {d_model}, Number of heads: {num_heads}\\n{d_model} is not divisible by {num_heads}.\"\n",
    "        self.heads = num_heads\n",
    "\n",
    "    def forward(self, encoded_embedding):\n",
    "        num_batches, seq_length, d_model = encoded_embedding.shape\n",
    "        batches = encoded_embedding\n",
    "        return batches, num_batches, seq_length, d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nNumber of embedding dimensions is not divisible by the number of heads.\nEmbedding dimensions (d_model): 512, Number of heads: 9\n512 is not divisible by 9.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mheadV1 \u001b[38;5;241m=\u001b[39m \u001b[43mMultiHeadAttentionV1\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m, in \u001b[0;36mMultiHeadAttentionV1.__init__\u001b[0;34m(self, d_model, num_heads)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, d_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m d_model \u001b[38;5;241m%\u001b[39m num_heads \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNumber of embedding dimensions is not divisible by the number of heads.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEmbedding dimensions (d_model): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Number of heads: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_heads\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00md_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not divisible by \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_heads\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads \u001b[38;5;241m=\u001b[39m num_heads\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNumber of embedding dimensions is not divisible by the number of heads.\nEmbedding dimensions (d_model): 512, Number of heads: 9\n512 is not divisible by 9."
     ]
    }
   ],
   "source": [
    "mheadV1 = MultiHeadAttentionV1(d_model=d_model, num_heads=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiHeadV1 = MultiHeadAttentionV1(d_model=d_model, num_heads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches' shape: torch.Size([2, 4, 512])\n",
      "i.e., 2 batches of 4 tokens each, each token of dimensions 512.\n",
      "\n",
      "Batches:\n",
      "tensor([[[ 0.8917,  2.3933, -0.8909,  ..., -0.2700, -1.5286, -0.7189],\n",
      "         [ 0.1638,  0.1830,  0.6913,  ..., -1.6652, -0.0245,  1.3272],\n",
      "         [ 0.3861, -0.6231,  1.9998,  ...,  0.9808, -1.4332,  2.5941],\n",
      "         [-0.5816,  0.5846,  0.6392,  ...,  1.0488,  0.0632,  1.7642]],\n",
      "\n",
      "        [[ 0.2053,  0.3284,  1.1073,  ..., -0.2991, -0.6190,  0.9162],\n",
      "         [ 1.1671,  0.2548,  0.6279,  ...,  0.8210,  1.5053,  2.8777],\n",
      "         [ 1.7027,  1.2783,  1.4984,  ...,  1.1618, -0.0089,  0.3586],\n",
      "         [ 0.2827, -2.4418,  0.9011,  ...,  2.0058,  0.8063,  1.1839]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batches, batch_size, seq_length, d_model = multiHeadV1(encoded_embedding)\n",
    "print(\n",
    "    f\"\"\"Batches' shape: {batches.shape}\n",
    "i.e., {batch_size} batches of {seq_length} tokens each, each token of dimensions {d_model}.\n",
    "\n",
    "Batches:\n",
    "{batches}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
